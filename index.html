<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="We introduce the first autonomous LLM agent which we call "reason for future, act for now" with provable regret guarantees and outstanding empirical performances.">
  <meta name="keywords" content="Large Language Model, Agent">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=uEl_TtkAAAAJ&hl=en">Zhihan Liu</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a href="http://mousehu.cn/">Hao Hu</a><sup>*2</sup>,</span>
            <span class="author-block">
              <a href="https://shenao-zhang.github.io/">Shenao Zhang</a><sup>*1</sup>,</span>
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=bzPCv_8AAAAJ&hl=en">Hongyi Guo</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Shuqi_Ke1">Shuqi Ke</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=1G8RH_YAAAAJ&hl=en">Boyi Liu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://zhaoranwang.github.io/">Zhaoran Wang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Northwestern University,</span>
            <span class="author-block"><sup>2</sup>Tsinghua University,</span>
            <span class="author-block"><sup>3</sup>The Chinese University of Hong Kong</span><br>
			      <small>(* indicates equal contribution)</small><br>
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2309.17382.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2309.17382"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/agentification/RAFA_code"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/askforalfred/alfred"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <b>Overview:</b> We introduce the first autonomous LLM agent which we call "reason for future, act for now" (<span class="dnerf">RAFA</span>) with provable regret guarantees and outstanding empirical performances.
      </h2>
      <img src="./static/images/intro.svg" width="100%"/>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>Large language models (LLMs) demonstrate impressive reasoning abilities, but translating reasoning into actions in the real world remains challenging. In particular, it remains unclear how to complete a given task provably within a minimum number of interactions with the external environment, e.g., through an internal mechanism of reasoning. To this end, we propose a principled framework with provable regret guarantees to orchestrate reasoning and acting, which we call "reason for future, act for now" (<span class="dnerf">RAFA</span>). Specifically, we design a prompt template for reasoning that learns from the memory buffer and plans a future trajectory over a long horizon ("reason for future"). At each step, the LLM agent takes the initial action of the planned trajectory ("act for now"), stores the collected feedback in the memory buffer, and reinvokes the reasoning routine to replan the future trajectory from the new state.
          </p>
          <p>The key idea is to cast reasoning in LLMs as learning and planning in Bayesian adaptive Markov decision processes (MDPs). Correspondingly, we prompt LLMs to form an updated posterior of the unknown environment from the memory buffer (learning) and generate an optimal trajectory for multiple future steps that maximizes a value function (planning). The learning and planning subroutines are performed in an "in-context" manner to emulate the actor-critic update for MDPs. Our theoretical analysis proves that the novel combination of long-term reasoning and short-term acting achieves a √T regret. In particular, the regret bound highlights an intriguing interplay between the prior knowledge obtained through pretraining and the uncertainty reduction achieved by reasoning and acting. Our empirical validation shows that it outperforms various existing frameworks and achieves nearly perfect scores on a few benchmarks. By incorporating “classical” MDP techniques, RAFA introduces the first autonomous LLM agent with provable regret guarantees. Notably, LLMs do not function as actors, critics, or learned world models, but rather as an internal mechanism that improves them iteratively.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
	<div class="columns is-centered">
	<figure>
        <img src="./static/images/algo1.jpg"/>
	</figure>
	</div>
        <div class="content has-text-justified">
          <p>At the t-th step of RAFA (Algorithm 1), the LLM agent invokes the reasoning routine, which learns from the memory buffer and plans a future trajectory over a long horizon ("reason for future" in Line 6), takes the initial action of the planned trajectory (“act for now” in Line 7), and stores the collected feedback (state, action, and reward) in the memory buffer (Line 8). Upon the state transition of the external environment, the LLM agent reinvokes the reasoning routine to replan another future trajectory from the new state (Line 6 following Line 9). To ensure the learning and planning stability, we impose the switching condition (Line 10) to decide whether to incorporate the newest chunk of history into the information state, which is used in the reasoning routine as contexts. For different concrete settings, we use different implementations of the LLM learner-planner. Please check our paper for more details.
          </p>
        <h2 class="title is-3">Experimental Results</h2>
	<p>Our empirical validation shows that RAFA outperforms various existing frameworks in interactive decision-making tasks, including ALFWorld, BlocksWorld, Game of 24, and a new benchmark based on TicTacToe. In a few benchmarks, it achieves nearly perfect scores.</p>
        <h3 class="title is-4">(a) Game of 24</h3>
	<p>Game of 24 is a mathematical puzzle to obtain 24 from four natural numbers through basic arithmetic operations. RAFA uses the beam search planner (Algorithm 4 in our paper) on Game of 24.</p>
		<div class="columns is-centered">
		<figure>
    		<img src="./static/images/demo_24.gif" height="120%" width="120%"/>
		</figure>
		</div>
		<figure>
    		<img src="./static/images/result_24.jpg" width="100%"/>
		<figcaption style="text-align: center; color: #888;">
		    Results on Game of 24.
  		</figcaption>
		</figure>
        <h3 class="title is-4">(b) ALFWorld</h3>
	<p>ALFWorld is an interactive environment for embodied agent simulations, which encompasses 134 household tasks in six overall categories. RAFA uses the tree-search planner (Algorithm 2 in our paper) on ALFWorld.</p>
	<div class="columns is-centered">
		<figure>
    		<img src="./static/images/demo_alf.gif" height="100%" width="100%"/>
		</figure>
	</div>
	      
	      	<figure>
    		<img src="./static/images/combine_alf.svg" width="100%"/>
		<figcaption style="text-align: center; color: #888;">
		    Results on ALFWorld.
  		</figcaption>
		</figure>
        <h3 class="title is-4">(c) BlocksWorld</h3>
	<p>BlocksWorld contains tasks to arrange blocks in specific configurations. RAFA uses the MCTS planner (Algorithm 5 in our paper) on BlocksWorld.</p>
	<div class="columns is-centered">
		<figure>
    		<img src="./static/images/demo_blocks.gif" height="80%" width="80%"/>
		</figure>
	</div>
	      	<figure>
    		<img src="./static/images/result_blocks1.jpg" width="100%"/>
		<img src="./static/images/result_blocks2.jpg" width="100%"/>
		<figcaption style="text-align: center; color: #888;">
      Results on BlocksWorld.
  		</figcaption>
		</figure>

        <h3 class="title is-4">(d) Tic-Tac-Toe</h3>
	<p>Tic-Tac-Toe is a competitive game where the X and O sides take turns to place marks. RAFA uses the MCTS planner (Algorithm 5 in our paper) on Tic-Tac-Toe.</p>
		<div class="columns is-centered">
		<figure>
    		<img src="./static/images/illu_ttt.gif" height="100%" width="100%"/>
		</figure>
		</div>
		<div class="columns is-centered">
		<figure>
    		<img src="./static/images/demo_ttt.gif" height="45%" width="45%"/>
		</figure>
		</div>
	      	<figure>
    		<img src="./static/images/combine_ttt.svg" width="100%"/>
		<figcaption style="text-align: center; color: #888;">
		    Results on Tic-Tac-Toe.
  		</figcaption>
		</figure>
		</figure>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{liu2023reason,
      title={Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency},
      author={Liu, Zhihan and Hu, Hao and Zhang, Shenao and Guo, Hongyi and Ke, Shuqi and Liu, Boyi and Wang, Zhaoran},
      journal={arXiv preprint arXiv:2309.17382},
      year={2023}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="content has-text-justified">
        <p>
         We acknowledge <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> for the website template.
        </p>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
